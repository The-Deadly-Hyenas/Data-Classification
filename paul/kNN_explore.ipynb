{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.combine import SMOTEENN\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the data and reset index of dataframe\n",
    "df: pd.DataFrame = pd.read_pickle(\n",
    "    \"../training_dataset_task3/task_3_training_e8da4715deef7d56_f8b7378_pandas.pkl\").reset_index()\n",
    "\n",
    "# get only the low and mid level features + segment_id\n",
    "X = df.loc[:, \"essentia_dissonance_mean\":\"mirtoolbox_roughness_pct_90\"]\n",
    "# target value\n",
    "y = df[\"quadrant\"]\n",
    "\n",
    "# preprocess dataset\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X_std, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features that have a correlation above some threshold\n",
    "from itertools import combinations\n",
    "\n",
    "corr_df = X.corr()\n",
    "\n",
    "feature_combis = combinations(corr_df.columns, 2)\n",
    "n_combis = len(list(combinations(corr_df.columns, 2)))\n",
    "\n",
    "corr_features = []\n",
    "\n",
    "for f1, f2 in feature_combis:\n",
    "    corr = corr_df[f1].loc[f2]\n",
    "    \n",
    "    # strong\n",
    "    if 0.9 <= abs(corr):\n",
    "        corr_features.append(dict([(\"corr\", corr), (\"feature 1\", f1), (\"feature 2\", f2)]))\n",
    "\n",
    "corr_features_df = pd.DataFrame(corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>feature 1</th>\n",
       "      <th>feature 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.997793</td>\n",
       "      <td>librosa_mfcc_mean_0</td>\n",
       "      <td>librosa_mfcc_pct_50_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.995234</td>\n",
       "      <td>mirtoolbox_roughness_mean</td>\n",
       "      <td>mirtoolbox_roughness_pct_50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.995038</td>\n",
       "      <td>librosa_mfcc_mean_2</td>\n",
       "      <td>librosa_mfcc_pct_50_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.994096</td>\n",
       "      <td>librosa_mfcc_mean_6</td>\n",
       "      <td>librosa_mfcc_pct_50_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.992734</td>\n",
       "      <td>librosa_mfcc_mean_7</td>\n",
       "      <td>librosa_mfcc_pct_50_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        corr                  feature 1                    feature 2\n",
       "18  0.997793        librosa_mfcc_mean_0        librosa_mfcc_pct_50_0\n",
       "87  0.995234  mirtoolbox_roughness_mean  mirtoolbox_roughness_pct_50\n",
       "35  0.995038        librosa_mfcc_mean_2        librosa_mfcc_pct_50_2\n",
       "55  0.994096        librosa_mfcc_mean_6        librosa_mfcc_pct_50_6\n",
       "60  0.992734        librosa_mfcc_mean_7        librosa_mfcc_pct_50_7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 5 positive correlation\n",
    "corr_features_df.sort_values(by=[\"corr\"], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>feature 1</th>\n",
       "      <th>feature 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.939749</td>\n",
       "      <td>midlevel_features_dissonance</td>\n",
       "      <td>midlevel_features_tonal_stability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.931481</td>\n",
       "      <td>midlevel_features_melody</td>\n",
       "      <td>midlevel_features_dissonance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.900357</td>\n",
       "      <td>librosa_mfcc_pct_50_5</td>\n",
       "      <td>librosa_mfcc_pct_90_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.901168</td>\n",
       "      <td>librosa_chroma_std_8</td>\n",
       "      <td>librosa_chroma_pct_90_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.901781</td>\n",
       "      <td>mirtoolbox_novelty_std</td>\n",
       "      <td>mirtoolbox_novelty_pct_90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        corr                     feature 1                          feature 2\n",
       "75 -0.939749  midlevel_features_dissonance  midlevel_features_tonal_stability\n",
       "74 -0.931481      midlevel_features_melody       midlevel_features_dissonance\n",
       "53  0.900357         librosa_mfcc_pct_50_5              librosa_mfcc_pct_90_5\n",
       "13  0.901168          librosa_chroma_std_8            librosa_chroma_pct_90_8\n",
       "85  0.901781        mirtoolbox_novelty_std          mirtoolbox_novelty_pct_90"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 5 negative correlation\n",
    "corr_features_df.sort_values(by=[\"corr\"], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add segment_id to data for filtering segments\n",
    "X[\"segment_id\"] = df[\"segment_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove segment_id 26 and keep as test/ eval data for later\n",
    "seg_26_indices = (X[\"segment_id\"] == 26)\n",
    "X_test = X[seg_26_indices].drop([\"segment_id\"], axis=1)\n",
    "y_test = y[seg_26_indices]\n",
    "\n",
    "X_train = X.drop(X[seg_26_indices].index, axis=0).reset_index(drop=True)\n",
    "y_train = y.drop(X[seg_26_indices].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Combination of over- and under-sampling\n",
    "# https://imbalanced-learn.org/stable/combine.html\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "# X_resampled, y_resampled = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split the data according to segment_id\n",
    "# store the splits as tuple (train indices, test_indices)\n",
    "# 2 segments for test, the rest for training (not including segment 26)\n",
    "cv = []\n",
    "\n",
    "for i in range(24):\n",
    "    train_indices = X_resampled[~X_resampled[\"segment_id\"].isin([i, i + 1])].index.to_list()\n",
    "    test_indices = X_resampled[X_resampled[\"segment_id\"].isin([i, i + 1])].index.to_list()\n",
    "    cv.append((train_indices, test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove the segment_id as we don't want it in the training data\n",
    "X_resampled = X_resampled.drop([\"segment_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select k best features according to ANOVA F-value between label/feature (for classification tasks)\n",
    "best_features = SelectKBest(score_func=f_classif, k=15).fit(X_resampled, y_resampled).get_feature_names_out()\n",
    "X_select = X_resampled[best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# parameters for grid search\n",
    "params = {\n",
    "    \"n_neighbors\": np.linspace(1, 300, 150, dtype=int).tolist(),\n",
    "    \"weights\": [\"uniform\"],  # {‘uniform’, ‘distance’}\n",
    "    \"algorithm\": [\"auto\"],  # {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}\n",
    "}\n",
    "\n",
    "gs_cv = GridSearchCV(KNeighborsClassifier(), params, cv=cv, return_train_score=True, n_jobs=-1)\n",
    "gs_cv.fit(X_select, y_resampled)\n",
    "print(gs_cv.best_score_, gs_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# results of the Grid Search CV\n",
    "cv_results = pd.DataFrame.from_dict(gs_cv.cv_results_)\n",
    "cv_results.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot the train and test error against number of neighbors\n",
    "fig = px.line(\n",
    "    cv_results,\n",
    "    x=\"param_n_neighbors\",\n",
    "    y=[\"mean_test_score\", \"mean_train_score\"],\n",
    "    title=\"Train and Test Error for an increasing number of neighbors\",\n",
    "    labels={\n",
    "        \"param_n_neighbors\": \"Number of Neighbors\",\n",
    "        \"mean_test_score\": \"Mean Test Score\",\n",
    "        \"mean_train_score\": \"Mean Train Score\",\n",
    "        \"value\": \"Accuracy\",\n",
    "    },\n",
    "    width=800,\n",
    "    height=400,\n",
    ")\n",
    "fig.update_traces(mode=\"lines\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# score on held out test set, segment 26\n",
    "gs_cv.score(X_test[best_features], y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}